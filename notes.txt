- bash script that sleeps in between calls in a for loop?
	- have to hard code class codes
		- can just put in file after scraping once
			- parse file and choose which params to scrape on based on cmd args?
	- test
- what do we want
	- search by build name
		- code and name
			- need some list of these (?)
			- prolly another table for these mappings?
	- search by time
	- search by day
	- name, section, etc.

avg of 1.5 min, and 75 entries from astro.
around 180 total class code
=> 270 min, 4.5 hours, 14k entries
- DO, laptop + bridged VM(s), mac + bridged VM(s)
~ 1 hour if use about 5 machines
	- merging data?


- see terpnav for searchbar stuff

MVP:
- can search by buildings and day/time

TODO: - order is fine
- basic front end
	- how do i style this...
	- pagination
	- donezo?
- unit tests
- api validation
- typescript?? xdxdxd
	+2
- autofill buildings... somehow
- darn it... we forgot to separate by semester
- is there a design pattern that will let us avoid setting up DB connextion each time?
	- decorator comes to mind first
- clean up scrape scripts (lint, async, mongo is inefficient rn, etc.) - CAN BE DONE LATER
	- jesus this code is disguisting
		- we should do this soon
- actually run scripts (~10 minutes per department, 180 departments... 30 hours...) - We can actually do this as we work on other stuff if we just get a sample of data


